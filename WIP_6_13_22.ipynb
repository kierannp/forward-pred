{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess COF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COF_data_path = '/Users/kieran/iMoDELS-supplements/data/raw-data/everything.csv'\n",
    "COF_data = pd.read_csv(COF_data_path, index_col=0)\n",
    "COF_data = COF_data.drop(['backbone'],axis=1)\n",
    "\n",
    "molecules = glob.glob('../terminal_group_screening/src/util/molecules/*.xyz')\n",
    "molecules = list(set(molecules))\n",
    "im_mols = {}\n",
    "for m in molecules:\n",
    "    mol_name = m.split('/')[-1].split('.')[0]\n",
    "    if 'ch3' in mol_name:\n",
    "        mol_name = mol_name.split('-')[0]\n",
    "        \n",
    "COD_data = COF_data.dropna()\n",
    "msk = np.random.rand(len(COF_data)) < 0.8\n",
    "\n",
    "train, test = COF_data[msk] , COF_data[~msk]\n",
    "train_X, train_y = train, train['COF']\n",
    "train_X = train_X.drop(['COF'],axis=1)\n",
    "test_X, test_y = test, test['COF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get QM9 property prediction working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'egnn'\n",
      "/Users/kieran/forward-pred/egnn\n"
     ]
    }
   ],
   "source": [
    "%cd egnn\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'egnn/models/egnn_clean')\n",
    "sys.path.insert(1, 'egnn/qm9')\n",
    "import qm9\n",
    "from qm9 import dataset\n",
    "from easydict import EasyDict as edict\n",
    "from qm9 import utils as qm9_utils\n",
    "from qm9.models import EGNN\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "args = edict({'batch_size':8, 'num_workers':2, 'dataset':'qm9', 'datadir':'/Users/kieran/forward-pred/qm9/data/qm9/qm9',\n",
    "            'filter_n_atoms':None, 'remove_h':True, 'include_charges':True, 'shuffle': True, 'property': 'alpha', 'nf':128,\n",
    "             'n_layers':7, 'attention':True, 'node_attr':0, 'lr':1e-3, 'weight_decay':1e-16, 'epochs':10, 'charge_power':2,\n",
    "             'test_interval':1, 'log_interval':20})\n",
    "args.cuda = False\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "dtype = torch.float32\n",
    "dataloaders, charge_scale = dataset.retrieve_dataloaders(args.batch_size)\n",
    "\n",
    "# compute mean and mean absolute deviation\n",
    "meann, mad = qm9_utils.compute_mean_mad(dataloaders, args.property)\n",
    "\n",
    "model = EGNN(in_node_nf=15, in_edge_nf=0, hidden_nf=args.nf, device=device, n_layers=args.n_layers, coords_weight=1.0,\n",
    "             attention=args.attention, node_attr=args.node_attr)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "loss_l1 = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, loader, partition='train'):\n",
    "    lr_scheduler.step()\n",
    "    res = {'loss': 0, 'counter': 0, 'loss_arr':[]}\n",
    "    for i, data in enumerate(loader):\n",
    "        if partition == 'train':\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        batch_size, n_nodes, _ = data['positions'].size()\n",
    "        atom_positions = data['positions'].view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "        atom_mask = data['atom_mask'].view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "        edge_mask = data['edge_mask'].to(device, dtype)\n",
    "        one_hot = data['one_hot'].to(device, dtype)\n",
    "        charges = data['charges'].to(device, dtype)\n",
    "        nodes = qm9_utils.preprocess_input(one_hot, charges, args.charge_power, charge_scale, device)\n",
    "\n",
    "        nodes = nodes.view(batch_size * n_nodes, -1)\n",
    "        # nodes = torch.cat([one_hot, charges], dim=1)\n",
    "        edges = qm9_utils.get_adj_matrix(n_nodes, batch_size, device)\n",
    "        label = data[args.property].to(device, dtype)\n",
    "\n",
    "        pred = model(h0=nodes, x=atom_positions, edges=edges, edge_attr=None, node_mask=atom_mask, edge_mask=edge_mask,\n",
    "                     n_nodes=n_nodes)\n",
    "\n",
    "        if partition == 'train':\n",
    "            loss = loss_l1(pred, (label - meann) / mad)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            loss = loss_l1(mad * pred + meann, label)\n",
    "\n",
    "        res['loss'] += loss.item() * batch_size\n",
    "        res['counter'] += batch_size\n",
    "        res['loss_arr'].append(loss.item())\n",
    "\n",
    "        prefix = \"\"\n",
    "        if partition != 'train':\n",
    "            prefix = \">> %s \\t\" % partition\n",
    "\n",
    "        if i % args.log_interval == 0:\n",
    "            print(prefix + \"Epoch %d \\t Iteration %d \\t loss %.4f\" % (epoch, i, sum(res['loss_arr'][-10:])/len(res['loss_arr'][-10:])))\n",
    "    return res['loss'] / res['counter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kieran/opt/miniconda3/envs/forward/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t Iteration 0 \t loss 0.3911\n",
      "Epoch 0 \t Iteration 20 \t loss 0.7245\n",
      "Epoch 0 \t Iteration 40 \t loss 0.6656\n",
      "Epoch 0 \t Iteration 60 \t loss 0.4734\n",
      "Epoch 0 \t Iteration 80 \t loss 0.5782\n",
      "Epoch 0 \t Iteration 100 \t loss 0.5039\n",
      "Epoch 0 \t Iteration 120 \t loss 0.4655\n",
      "Epoch 0 \t Iteration 140 \t loss 0.5755\n",
      "Epoch 0 \t Iteration 160 \t loss 0.6894\n",
      "Epoch 0 \t Iteration 180 \t loss 0.4543\n",
      "Epoch 0 \t Iteration 200 \t loss 0.5118\n",
      "Epoch 0 \t Iteration 220 \t loss 0.5031\n",
      "Epoch 0 \t Iteration 240 \t loss 0.3978\n",
      "Epoch 0 \t Iteration 260 \t loss 0.4294\n",
      "Epoch 0 \t Iteration 280 \t loss 0.5825\n",
      "Epoch 0 \t Iteration 300 \t loss 0.5387\n",
      "Epoch 0 \t Iteration 320 \t loss 0.4653\n",
      "Epoch 0 \t Iteration 340 \t loss 0.4446\n",
      "Epoch 0 \t Iteration 360 \t loss 0.3655\n",
      "Epoch 0 \t Iteration 380 \t loss 0.3785\n",
      "Epoch 0 \t Iteration 400 \t loss 0.4293\n",
      "Epoch 0 \t Iteration 420 \t loss 0.4055\n",
      "Epoch 0 \t Iteration 440 \t loss 0.2688\n",
      "Epoch 0 \t Iteration 460 \t loss 0.4606\n",
      "Epoch 0 \t Iteration 480 \t loss 0.3924\n",
      "Epoch 0 \t Iteration 500 \t loss 0.4249\n",
      "Epoch 0 \t Iteration 520 \t loss 0.3527\n",
      "Epoch 0 \t Iteration 540 \t loss 0.4311\n",
      "Epoch 0 \t Iteration 560 \t loss 0.4032\n",
      "Epoch 0 \t Iteration 580 \t loss 0.4175\n",
      "Epoch 0 \t Iteration 600 \t loss 0.5288\n",
      "Epoch 0 \t Iteration 620 \t loss 0.5200\n",
      "Epoch 0 \t Iteration 640 \t loss 0.4016\n",
      "Epoch 0 \t Iteration 660 \t loss 0.5288\n",
      "Epoch 0 \t Iteration 680 \t loss 0.4035\n",
      "Epoch 0 \t Iteration 700 \t loss 0.4545\n",
      "Epoch 0 \t Iteration 720 \t loss 0.3814\n",
      "Epoch 0 \t Iteration 740 \t loss 0.4074\n",
      "Epoch 0 \t Iteration 760 \t loss 0.4183\n",
      "Epoch 0 \t Iteration 780 \t loss 0.3373\n",
      "Epoch 0 \t Iteration 800 \t loss 0.4136\n",
      "Epoch 0 \t Iteration 820 \t loss 0.3594\n",
      "Epoch 0 \t Iteration 840 \t loss 0.3416\n",
      "Epoch 0 \t Iteration 860 \t loss 0.3414\n",
      "Epoch 0 \t Iteration 880 \t loss 0.3981\n",
      "Epoch 0 \t Iteration 900 \t loss 0.3791\n",
      "Epoch 0 \t Iteration 920 \t loss 0.3514\n",
      "Epoch 0 \t Iteration 940 \t loss 0.3121\n",
      "Epoch 0 \t Iteration 960 \t loss 0.3142\n",
      "Epoch 0 \t Iteration 980 \t loss 0.4234\n",
      "Epoch 0 \t Iteration 1000 \t loss 0.4740\n",
      "Epoch 0 \t Iteration 1020 \t loss 0.4247\n",
      "Epoch 0 \t Iteration 1040 \t loss 0.3512\n",
      "Epoch 0 \t Iteration 1060 \t loss 0.4175\n",
      "Epoch 0 \t Iteration 1080 \t loss 0.4211\n",
      "Epoch 0 \t Iteration 1100 \t loss 0.3877\n",
      "Epoch 0 \t Iteration 1120 \t loss 0.3926\n",
      "Epoch 0 \t Iteration 1140 \t loss 0.3197\n",
      "Epoch 0 \t Iteration 1160 \t loss 0.3204\n",
      "Epoch 0 \t Iteration 1180 \t loss 0.3280\n",
      "Epoch 0 \t Iteration 1200 \t loss 0.3493\n",
      "Epoch 0 \t Iteration 1220 \t loss 0.3558\n",
      "Epoch 0 \t Iteration 1240 \t loss 0.2784\n",
      "Epoch 0 \t Iteration 1260 \t loss 0.2688\n",
      "Epoch 0 \t Iteration 1280 \t loss 0.3081\n",
      "Epoch 0 \t Iteration 1300 \t loss 0.3660\n",
      "Epoch 0 \t Iteration 1320 \t loss 0.3079\n",
      "Epoch 0 \t Iteration 1340 \t loss 0.3530\n",
      "Epoch 0 \t Iteration 1360 \t loss 0.4021\n",
      "Epoch 0 \t Iteration 1380 \t loss 0.3727\n",
      "Epoch 0 \t Iteration 1400 \t loss 0.4781\n",
      "Epoch 0 \t Iteration 1420 \t loss 0.3665\n",
      "Epoch 0 \t Iteration 1440 \t loss 0.4442\n",
      "Epoch 0 \t Iteration 1460 \t loss 0.3149\n",
      "Epoch 0 \t Iteration 1480 \t loss 0.3512\n",
      "Epoch 0 \t Iteration 1500 \t loss 0.3738\n",
      "Epoch 0 \t Iteration 1520 \t loss 0.3215\n",
      "Epoch 0 \t Iteration 1540 \t loss 0.5029\n",
      "Epoch 0 \t Iteration 1560 \t loss 0.3866\n",
      "Epoch 0 \t Iteration 1580 \t loss 0.2735\n",
      "Epoch 0 \t Iteration 1600 \t loss 0.3223\n",
      "Epoch 0 \t Iteration 1620 \t loss 0.2770\n",
      "Epoch 0 \t Iteration 1640 \t loss 0.4242\n",
      "Epoch 0 \t Iteration 1660 \t loss 0.3793\n",
      "Epoch 0 \t Iteration 1680 \t loss 0.4429\n",
      "Epoch 0 \t Iteration 1700 \t loss 0.2576\n",
      "Epoch 0 \t Iteration 1720 \t loss 0.2635\n",
      "Epoch 0 \t Iteration 1740 \t loss 0.3919\n",
      "Epoch 0 \t Iteration 1760 \t loss 0.4494\n",
      "Epoch 0 \t Iteration 1780 \t loss 0.3728\n",
      "Epoch 0 \t Iteration 1800 \t loss 0.3127\n",
      "Epoch 0 \t Iteration 1820 \t loss 0.2636\n",
      "Epoch 0 \t Iteration 1840 \t loss 0.2980\n",
      "Epoch 0 \t Iteration 1860 \t loss 0.2768\n",
      "Epoch 0 \t Iteration 1880 \t loss 0.3131\n",
      "Epoch 0 \t Iteration 1900 \t loss 0.4477\n",
      "Epoch 0 \t Iteration 1920 \t loss 0.2917\n",
      "Epoch 0 \t Iteration 1940 \t loss 0.2147\n",
      "Epoch 0 \t Iteration 1960 \t loss 0.3873\n",
      "Epoch 0 \t Iteration 1980 \t loss 0.3156\n",
      "Epoch 0 \t Iteration 2000 \t loss 0.3354\n",
      "Epoch 0 \t Iteration 2020 \t loss 0.3269\n",
      "Epoch 0 \t Iteration 2040 \t loss 0.2862\n",
      "Epoch 0 \t Iteration 2060 \t loss 0.3528\n",
      "Epoch 0 \t Iteration 2080 \t loss 0.3564\n",
      "Epoch 0 \t Iteration 2100 \t loss 0.5203\n",
      "Epoch 0 \t Iteration 2120 \t loss 0.2987\n",
      "Epoch 0 \t Iteration 2140 \t loss 0.3123\n",
      "Epoch 0 \t Iteration 2160 \t loss 0.2481\n",
      "Epoch 0 \t Iteration 2180 \t loss 0.3177\n",
      "Epoch 0 \t Iteration 2200 \t loss 0.3711\n",
      "Epoch 0 \t Iteration 2220 \t loss 0.3916\n",
      "Epoch 0 \t Iteration 2240 \t loss 0.2245\n",
      "Epoch 0 \t Iteration 2260 \t loss 0.2928\n",
      "Epoch 0 \t Iteration 2280 \t loss 0.2918\n",
      "Epoch 0 \t Iteration 2300 \t loss 0.2840\n",
      "Epoch 0 \t Iteration 2320 \t loss 0.4092\n",
      "Epoch 0 \t Iteration 2340 \t loss 0.3698\n",
      "Epoch 0 \t Iteration 2360 \t loss 0.2787\n",
      "Epoch 0 \t Iteration 2380 \t loss 0.2712\n",
      "Epoch 0 \t Iteration 2400 \t loss 0.2499\n",
      "Epoch 0 \t Iteration 2420 \t loss 0.2555\n",
      "Epoch 0 \t Iteration 2440 \t loss 0.3818\n",
      "Epoch 0 \t Iteration 2460 \t loss 0.2700\n",
      "Epoch 0 \t Iteration 2480 \t loss 0.3329\n",
      "Epoch 0 \t Iteration 2500 \t loss 0.2880\n",
      "Epoch 0 \t Iteration 2520 \t loss 0.3862\n",
      "Epoch 0 \t Iteration 2540 \t loss 0.2504\n",
      "Epoch 0 \t Iteration 2560 \t loss 0.3018\n",
      "Epoch 0 \t Iteration 2580 \t loss 0.2817\n",
      "Epoch 0 \t Iteration 2600 \t loss 0.2005\n",
      "Epoch 0 \t Iteration 2620 \t loss 0.2524\n",
      "Epoch 0 \t Iteration 2640 \t loss 0.3662\n",
      "Epoch 0 \t Iteration 2660 \t loss 0.3785\n",
      "Epoch 0 \t Iteration 2680 \t loss 0.2432\n",
      "Epoch 0 \t Iteration 2700 \t loss 0.2773\n",
      "Epoch 0 \t Iteration 2720 \t loss 0.2541\n",
      "Epoch 0 \t Iteration 2740 \t loss 0.1969\n",
      "Epoch 0 \t Iteration 2760 \t loss 0.2612\n",
      "Epoch 0 \t Iteration 2780 \t loss 0.2697\n",
      "Epoch 0 \t Iteration 2800 \t loss 0.3686\n",
      "Epoch 0 \t Iteration 2820 \t loss 0.2569\n",
      "Epoch 0 \t Iteration 2840 \t loss 0.3431\n",
      "Epoch 0 \t Iteration 2860 \t loss 0.2398\n",
      "Epoch 0 \t Iteration 2880 \t loss 0.2346\n",
      "Epoch 0 \t Iteration 2900 \t loss 0.2399\n",
      "Epoch 0 \t Iteration 2920 \t loss 0.2927\n",
      "Epoch 0 \t Iteration 2940 \t loss 0.3030\n",
      "Epoch 0 \t Iteration 2960 \t loss 0.3771\n",
      "Epoch 0 \t Iteration 2980 \t loss 0.2690\n",
      "Epoch 0 \t Iteration 3000 \t loss 0.2642\n",
      "Epoch 0 \t Iteration 3020 \t loss 0.2585\n",
      "Epoch 0 \t Iteration 3040 \t loss 0.2098\n",
      "Epoch 0 \t Iteration 3060 \t loss 0.2394\n",
      "Epoch 0 \t Iteration 3080 \t loss 0.2717\n",
      "Epoch 0 \t Iteration 3100 \t loss 0.3370\n",
      "Epoch 0 \t Iteration 3120 \t loss 0.3184\n",
      "Epoch 0 \t Iteration 3140 \t loss 0.2414\n",
      "Epoch 0 \t Iteration 3160 \t loss 0.3003\n",
      "Epoch 0 \t Iteration 3180 \t loss 0.3051\n",
      "Epoch 0 \t Iteration 3200 \t loss 0.2592\n",
      "Epoch 0 \t Iteration 3220 \t loss 0.2636\n",
      "Epoch 0 \t Iteration 3240 \t loss 0.2634\n",
      "Epoch 0 \t Iteration 3260 \t loss 0.3329\n",
      "Epoch 0 \t Iteration 3280 \t loss 0.2244\n",
      "Epoch 0 \t Iteration 3300 \t loss 0.2481\n",
      "Epoch 0 \t Iteration 3320 \t loss 0.2642\n",
      "Epoch 0 \t Iteration 3340 \t loss 0.2841\n",
      "Epoch 0 \t Iteration 3360 \t loss 0.2739\n",
      "Epoch 0 \t Iteration 3380 \t loss 0.3995\n",
      "Epoch 0 \t Iteration 3400 \t loss 0.2917\n",
      "Epoch 0 \t Iteration 3420 \t loss 0.2827\n",
      "Epoch 0 \t Iteration 3440 \t loss 0.2890\n",
      "Epoch 0 \t Iteration 3460 \t loss 0.2232\n",
      "Epoch 0 \t Iteration 3480 \t loss 0.3042\n",
      "Epoch 0 \t Iteration 3500 \t loss 0.3458\n",
      "Epoch 0 \t Iteration 3520 \t loss 0.2505\n",
      "Epoch 0 \t Iteration 3540 \t loss 0.2026\n",
      "Epoch 0 \t Iteration 3560 \t loss 0.2504\n",
      "Epoch 0 \t Iteration 3580 \t loss 0.2789\n",
      "Epoch 0 \t Iteration 3600 \t loss 0.2074\n",
      "Epoch 0 \t Iteration 3620 \t loss 0.2477\n",
      "Epoch 0 \t Iteration 3640 \t loss 0.2043\n",
      "Epoch 0 \t Iteration 3660 \t loss 0.3287\n",
      "Epoch 0 \t Iteration 3680 \t loss 0.3666\n",
      "Epoch 0 \t Iteration 3700 \t loss 0.2877\n",
      "Epoch 0 \t Iteration 3720 \t loss 0.1992\n",
      "Epoch 0 \t Iteration 3740 \t loss 0.2531\n",
      "Epoch 0 \t Iteration 3760 \t loss 0.2846\n",
      "Epoch 0 \t Iteration 3780 \t loss 0.3756\n",
      "Epoch 0 \t Iteration 3800 \t loss 0.2037\n",
      "Epoch 0 \t Iteration 3820 \t loss 0.2664\n",
      "Epoch 0 \t Iteration 3840 \t loss 0.2542\n",
      "Epoch 0 \t Iteration 3860 \t loss 0.2616\n",
      "Epoch 0 \t Iteration 3880 \t loss 0.2862\n",
      "Epoch 0 \t Iteration 3900 \t loss 0.3113\n",
      "Epoch 0 \t Iteration 3920 \t loss 0.2190\n",
      "Epoch 0 \t Iteration 3940 \t loss 0.3343\n",
      "Epoch 0 \t Iteration 3960 \t loss 0.2710\n",
      "Epoch 0 \t Iteration 3980 \t loss 0.2393\n",
      "Epoch 0 \t Iteration 4000 \t loss 0.2513\n",
      "Epoch 0 \t Iteration 4020 \t loss 0.2400\n",
      "Epoch 0 \t Iteration 4040 \t loss 0.1923\n",
      "Epoch 0 \t Iteration 4060 \t loss 0.2057\n",
      "Epoch 0 \t Iteration 4080 \t loss 0.2311\n",
      "Epoch 0 \t Iteration 4100 \t loss 0.3893\n",
      "Epoch 0 \t Iteration 4120 \t loss 0.2280\n",
      "Epoch 0 \t Iteration 4140 \t loss 0.2563\n",
      "Epoch 0 \t Iteration 4160 \t loss 0.2726\n",
      "Epoch 0 \t Iteration 4180 \t loss 0.2968\n",
      "Epoch 0 \t Iteration 4200 \t loss 0.2414\n",
      "Epoch 0 \t Iteration 4220 \t loss 0.2657\n",
      "Epoch 0 \t Iteration 4240 \t loss 0.2317\n",
      "Epoch 0 \t Iteration 4260 \t loss 0.2802\n",
      "Epoch 0 \t Iteration 4280 \t loss 0.3242\n",
      "Epoch 0 \t Iteration 4300 \t loss 0.2796\n",
      "Epoch 0 \t Iteration 4320 \t loss 0.1994\n",
      "Epoch 0 \t Iteration 4340 \t loss 0.2751\n",
      "Epoch 0 \t Iteration 4360 \t loss 0.2333\n",
      "Epoch 0 \t Iteration 4380 \t loss 0.2406\n",
      "Epoch 0 \t Iteration 4400 \t loss 0.3290\n",
      "Epoch 0 \t Iteration 4420 \t loss 0.2739\n",
      "Epoch 0 \t Iteration 4440 \t loss 0.2347\n",
      "Epoch 0 \t Iteration 4460 \t loss 0.2300\n",
      "Epoch 0 \t Iteration 4480 \t loss 0.2672\n",
      "Epoch 0 \t Iteration 4500 \t loss 0.3037\n",
      "Epoch 0 \t Iteration 4520 \t loss 0.2094\n",
      "Epoch 0 \t Iteration 4540 \t loss 0.2000\n",
      "Epoch 0 \t Iteration 4560 \t loss 0.3235\n",
      "Epoch 0 \t Iteration 4580 \t loss 0.2801\n",
      "Epoch 0 \t Iteration 4600 \t loss 0.2254\n",
      "Epoch 0 \t Iteration 4620 \t loss 0.2688\n",
      "Epoch 0 \t Iteration 4640 \t loss 0.2978\n",
      "Epoch 0 \t Iteration 4660 \t loss 0.2938\n",
      "Epoch 0 \t Iteration 4680 \t loss 0.2344\n",
      "Epoch 0 \t Iteration 4700 \t loss 0.2700\n",
      "Epoch 0 \t Iteration 4720 \t loss 0.2807\n",
      "Epoch 0 \t Iteration 4740 \t loss 0.2453\n",
      "Epoch 0 \t Iteration 4760 \t loss 0.2084\n",
      "Epoch 0 \t Iteration 4780 \t loss 0.2386\n",
      "Epoch 0 \t Iteration 4800 \t loss 0.2326\n",
      "Epoch 0 \t Iteration 4820 \t loss 0.2023\n",
      "Epoch 0 \t Iteration 4840 \t loss 0.2395\n",
      "Epoch 0 \t Iteration 4860 \t loss 0.2653\n",
      "Epoch 0 \t Iteration 4880 \t loss 0.2713\n",
      "Epoch 0 \t Iteration 4900 \t loss 0.2241\n",
      "Epoch 0 \t Iteration 4920 \t loss 0.2898\n",
      "Epoch 0 \t Iteration 4940 \t loss 0.2278\n",
      "Epoch 0 \t Iteration 4960 \t loss 0.2245\n",
      "Epoch 0 \t Iteration 4980 \t loss 0.1927\n",
      "Epoch 0 \t Iteration 5000 \t loss 0.2367\n",
      "Epoch 0 \t Iteration 5020 \t loss 0.2253\n",
      "Epoch 0 \t Iteration 5040 \t loss 0.3494\n",
      "Epoch 0 \t Iteration 5060 \t loss 0.2784\n",
      "Epoch 0 \t Iteration 5080 \t loss 0.2582\n",
      "Epoch 0 \t Iteration 5100 \t loss 0.2477\n",
      "Epoch 0 \t Iteration 5120 \t loss 0.3057\n",
      "Epoch 0 \t Iteration 5140 \t loss 0.3060\n",
      "Epoch 0 \t Iteration 5160 \t loss 0.2079\n",
      "Epoch 0 \t Iteration 5180 \t loss 0.2381\n",
      "Epoch 0 \t Iteration 5200 \t loss 0.3166\n",
      "Epoch 0 \t Iteration 5220 \t loss 0.2730\n",
      "Epoch 0 \t Iteration 5240 \t loss 0.2732\n",
      "Epoch 0 \t Iteration 5260 \t loss 0.2979\n",
      "Epoch 0 \t Iteration 5280 \t loss 0.2069\n",
      "Epoch 0 \t Iteration 5300 \t loss 0.3057\n",
      "Epoch 0 \t Iteration 5320 \t loss 0.2002\n",
      "Epoch 0 \t Iteration 5340 \t loss 0.2571\n",
      "Epoch 0 \t Iteration 5360 \t loss 0.2197\n",
      "Epoch 0 \t Iteration 5380 \t loss 0.2677\n",
      "Epoch 0 \t Iteration 5400 \t loss 0.2196\n",
      "Epoch 0 \t Iteration 5420 \t loss 0.2135\n",
      "Epoch 0 \t Iteration 5440 \t loss 0.2315\n",
      "Epoch 0 \t Iteration 5460 \t loss 0.2867\n",
      "Epoch 0 \t Iteration 5480 \t loss 0.2533\n",
      "Epoch 0 \t Iteration 5500 \t loss 0.2309\n",
      "Epoch 0 \t Iteration 5520 \t loss 0.3071\n",
      "Epoch 0 \t Iteration 5540 \t loss 0.2035\n",
      "Epoch 0 \t Iteration 5560 \t loss 0.2246\n",
      "Epoch 0 \t Iteration 5580 \t loss 0.2994\n",
      "Epoch 0 \t Iteration 5600 \t loss 0.1901\n",
      "Epoch 0 \t Iteration 5620 \t loss 0.2302\n",
      "Epoch 0 \t Iteration 5640 \t loss 0.2093\n",
      "Epoch 0 \t Iteration 5660 \t loss 0.2732\n",
      "Epoch 0 \t Iteration 5680 \t loss 0.2983\n",
      "Epoch 0 \t Iteration 5700 \t loss 0.2461\n",
      "Epoch 0 \t Iteration 5720 \t loss 0.1910\n",
      "Epoch 0 \t Iteration 5740 \t loss 0.2888\n",
      "Epoch 0 \t Iteration 5760 \t loss 0.2131\n",
      "Epoch 0 \t Iteration 5780 \t loss 0.1699\n",
      "Epoch 0 \t Iteration 5800 \t loss 0.2952\n",
      "Epoch 0 \t Iteration 5820 \t loss 0.2109\n",
      "Epoch 0 \t Iteration 5840 \t loss 0.2173\n",
      "Epoch 0 \t Iteration 5860 \t loss 0.3389\n",
      "Epoch 0 \t Iteration 5880 \t loss 0.3022\n",
      "Epoch 0 \t Iteration 5900 \t loss 0.2342\n",
      "Epoch 0 \t Iteration 5920 \t loss 0.2396\n",
      "Epoch 0 \t Iteration 5940 \t loss 0.2129\n",
      "Epoch 0 \t Iteration 5960 \t loss 0.2731\n",
      "Epoch 0 \t Iteration 5980 \t loss 0.2172\n",
      "Epoch 0 \t Iteration 6000 \t loss 0.2883\n",
      "Epoch 0 \t Iteration 6020 \t loss 0.2165\n",
      "Epoch 0 \t Iteration 6040 \t loss 0.2838\n",
      "Epoch 0 \t Iteration 6060 \t loss 0.2014\n",
      "Epoch 0 \t Iteration 6080 \t loss 0.2297\n",
      "Epoch 0 \t Iteration 6100 \t loss 0.2190\n",
      "Epoch 0 \t Iteration 6120 \t loss 0.2133\n",
      "Epoch 0 \t Iteration 6140 \t loss 0.2735\n",
      "Epoch 0 \t Iteration 6160 \t loss 0.2901\n",
      "Epoch 0 \t Iteration 6180 \t loss 0.2097\n",
      "Epoch 0 \t Iteration 6200 \t loss 0.2252\n",
      "Epoch 0 \t Iteration 6220 \t loss 0.1912\n",
      "Epoch 0 \t Iteration 6240 \t loss 0.2443\n",
      "Epoch 0 \t Iteration 6260 \t loss 0.2313\n",
      "Epoch 0 \t Iteration 6280 \t loss 0.2074\n",
      "Epoch 0 \t Iteration 6300 \t loss 0.2624\n",
      "Epoch 0 \t Iteration 6320 \t loss 0.2136\n",
      "Epoch 0 \t Iteration 6340 \t loss 0.2528\n",
      "Epoch 0 \t Iteration 6360 \t loss 0.2493\n",
      "Epoch 0 \t Iteration 6380 \t loss 0.2767\n",
      "Epoch 0 \t Iteration 6400 \t loss 0.3327\n",
      "Epoch 0 \t Iteration 6420 \t loss 0.2112\n",
      "Epoch 0 \t Iteration 6440 \t loss 0.3061\n",
      "Epoch 0 \t Iteration 6460 \t loss 0.2615\n",
      "Epoch 0 \t Iteration 6480 \t loss 0.2380\n",
      "Epoch 0 \t Iteration 6500 \t loss 0.2414\n",
      "Epoch 0 \t Iteration 6520 \t loss 0.2460\n",
      "Epoch 0 \t Iteration 6540 \t loss 0.2708\n",
      "Epoch 0 \t Iteration 6560 \t loss 0.2632\n",
      "Epoch 0 \t Iteration 6580 \t loss 0.1704\n",
      "Epoch 0 \t Iteration 6600 \t loss 0.2444\n",
      "Epoch 0 \t Iteration 6620 \t loss 0.2526\n",
      "Epoch 0 \t Iteration 6640 \t loss 0.2098\n",
      "Epoch 0 \t Iteration 6660 \t loss 0.1915\n",
      "Epoch 0 \t Iteration 6680 \t loss 0.2367\n",
      "Epoch 0 \t Iteration 6700 \t loss 0.2815\n",
      "Epoch 0 \t Iteration 6720 \t loss 0.2517\n",
      "Epoch 0 \t Iteration 6740 \t loss 0.2138\n",
      "Epoch 0 \t Iteration 6760 \t loss 0.3097\n",
      "Epoch 0 \t Iteration 6780 \t loss 0.2166\n",
      "Epoch 0 \t Iteration 6800 \t loss 0.2066\n",
      "Epoch 0 \t Iteration 6820 \t loss 0.1805\n",
      "Epoch 0 \t Iteration 6840 \t loss 0.2068\n",
      "Epoch 0 \t Iteration 6860 \t loss 0.2363\n",
      "Epoch 0 \t Iteration 6880 \t loss 0.2215\n",
      "Epoch 0 \t Iteration 6900 \t loss 0.1997\n",
      "Epoch 0 \t Iteration 6920 \t loss 0.2515\n",
      "Epoch 0 \t Iteration 6940 \t loss 0.2623\n",
      "Epoch 0 \t Iteration 6960 \t loss 0.1946\n",
      "Epoch 0 \t Iteration 6980 \t loss 0.2168\n",
      "Epoch 0 \t Iteration 7000 \t loss 0.2235\n",
      "Epoch 0 \t Iteration 7020 \t loss 0.2589\n",
      "Epoch 0 \t Iteration 7040 \t loss 0.2768\n",
      "Epoch 0 \t Iteration 7060 \t loss 0.1822\n",
      "Epoch 0 \t Iteration 7080 \t loss 0.2575\n",
      "Epoch 0 \t Iteration 7100 \t loss 0.2732\n",
      "Epoch 0 \t Iteration 7120 \t loss 0.2180\n",
      "Epoch 0 \t Iteration 7140 \t loss 0.2810\n",
      "Epoch 0 \t Iteration 7160 \t loss 0.2543\n",
      "Epoch 0 \t Iteration 7180 \t loss 0.2297\n",
      "Epoch 0 \t Iteration 7200 \t loss 0.2134\n",
      "Epoch 0 \t Iteration 7220 \t loss 0.2540\n",
      "Epoch 0 \t Iteration 7240 \t loss 0.2225\n",
      "Epoch 0 \t Iteration 7260 \t loss 0.2821\n",
      "Epoch 0 \t Iteration 7280 \t loss 0.2624\n",
      "Epoch 0 \t Iteration 7300 \t loss 0.1794\n",
      "Epoch 0 \t Iteration 7320 \t loss 0.2686\n",
      "Epoch 0 \t Iteration 7340 \t loss 0.2969\n",
      "Epoch 0 \t Iteration 7360 \t loss 0.1920\n",
      "Epoch 0 \t Iteration 7380 \t loss 0.1698\n",
      "Epoch 0 \t Iteration 7400 \t loss 0.3400\n",
      "Epoch 0 \t Iteration 7420 \t loss 0.2661\n",
      "Epoch 0 \t Iteration 7440 \t loss 0.2110\n",
      "Epoch 0 \t Iteration 7460 \t loss 0.2109\n",
      "Epoch 0 \t Iteration 7480 \t loss 0.2266\n",
      "Epoch 0 \t Iteration 7500 \t loss 0.2048\n",
      "Epoch 0 \t Iteration 7520 \t loss 0.2378\n",
      "Epoch 0 \t Iteration 7540 \t loss 0.2029\n",
      "Epoch 0 \t Iteration 7560 \t loss 0.2124\n",
      "Epoch 0 \t Iteration 7580 \t loss 0.2344\n",
      "Epoch 0 \t Iteration 7600 \t loss 0.2960\n",
      "Epoch 0 \t Iteration 7620 \t loss 0.2512\n",
      "Epoch 0 \t Iteration 7640 \t loss 0.2470\n",
      "Epoch 0 \t Iteration 7660 \t loss 0.1926\n",
      "Epoch 0 \t Iteration 7680 \t loss 0.1861\n",
      "Epoch 0 \t Iteration 7700 \t loss 0.2052\n",
      "Epoch 0 \t Iteration 7720 \t loss 0.2418\n",
      "Epoch 0 \t Iteration 7740 \t loss 0.2620\n",
      "Epoch 0 \t Iteration 7760 \t loss 0.3120\n",
      "Epoch 0 \t Iteration 7780 \t loss 0.2277\n",
      "Epoch 0 \t Iteration 7800 \t loss 0.1905\n",
      "Epoch 0 \t Iteration 7820 \t loss 0.2414\n",
      "Epoch 0 \t Iteration 7840 \t loss 0.2721\n",
      "Epoch 0 \t Iteration 7860 \t loss 0.2371\n",
      "Epoch 0 \t Iteration 7880 \t loss 0.2127\n",
      "Epoch 0 \t Iteration 7900 \t loss 0.2294\n",
      "Epoch 0 \t Iteration 7920 \t loss 0.1888\n",
      "Epoch 0 \t Iteration 7940 \t loss 0.4038\n",
      "Epoch 0 \t Iteration 7960 \t loss 0.1857\n",
      "Epoch 0 \t Iteration 7980 \t loss 0.2467\n",
      "Epoch 0 \t Iteration 8000 \t loss 0.1724\n",
      "Epoch 0 \t Iteration 8020 \t loss 0.2344\n",
      "Epoch 0 \t Iteration 8040 \t loss 0.2601\n",
      "Epoch 0 \t Iteration 8060 \t loss 0.2431\n",
      "Epoch 0 \t Iteration 8080 \t loss 0.2085\n",
      "Epoch 0 \t Iteration 8100 \t loss 0.2770\n",
      "Epoch 0 \t Iteration 8120 \t loss 0.2420\n",
      "Epoch 0 \t Iteration 8140 \t loss 0.2190\n",
      "Epoch 0 \t Iteration 8160 \t loss 0.2727\n",
      "Epoch 0 \t Iteration 8180 \t loss 0.1792\n",
      "Epoch 0 \t Iteration 8200 \t loss 0.2325\n",
      "Epoch 0 \t Iteration 8220 \t loss 0.2320\n",
      "Epoch 0 \t Iteration 8240 \t loss 0.2071\n",
      "Epoch 0 \t Iteration 8260 \t loss 0.1762\n",
      "Epoch 0 \t Iteration 8280 \t loss 0.2265\n",
      "Epoch 0 \t Iteration 8300 \t loss 0.3014\n",
      "Epoch 0 \t Iteration 8320 \t loss 0.2599\n",
      "Epoch 0 \t Iteration 8340 \t loss 0.2237\n",
      "Epoch 0 \t Iteration 8360 \t loss 0.1849\n",
      "Epoch 0 \t Iteration 8380 \t loss 0.2322\n",
      "Epoch 0 \t Iteration 8400 \t loss 0.2509\n",
      "Epoch 0 \t Iteration 8420 \t loss 0.2273\n",
      "Epoch 0 \t Iteration 8440 \t loss 0.1989\n",
      "Epoch 0 \t Iteration 8460 \t loss 0.1882\n",
      "Epoch 0 \t Iteration 8480 \t loss 0.2327\n",
      "Epoch 0 \t Iteration 8500 \t loss 0.1885\n",
      "Epoch 0 \t Iteration 8520 \t loss 0.1892\n",
      "Epoch 0 \t Iteration 8540 \t loss 0.2106\n",
      "Epoch 0 \t Iteration 8560 \t loss 0.1850\n",
      "Epoch 0 \t Iteration 8580 \t loss 0.1828\n",
      "Epoch 0 \t Iteration 8600 \t loss 0.1960\n",
      "Epoch 0 \t Iteration 8620 \t loss 0.2521\n",
      "Epoch 0 \t Iteration 8640 \t loss 0.2053\n",
      "Epoch 0 \t Iteration 8660 \t loss 0.2085\n",
      "Epoch 0 \t Iteration 8680 \t loss 0.1868\n",
      "Epoch 0 \t Iteration 8700 \t loss 0.1629\n",
      "Epoch 0 \t Iteration 8720 \t loss 0.1694\n",
      "Epoch 0 \t Iteration 8740 \t loss 0.2021\n",
      "Epoch 0 \t Iteration 8760 \t loss 0.1887\n",
      "Epoch 0 \t Iteration 8780 \t loss 0.2214\n",
      "Epoch 0 \t Iteration 8800 \t loss 0.1714\n",
      "Epoch 0 \t Iteration 8820 \t loss 0.2569\n",
      "Epoch 0 \t Iteration 8840 \t loss 0.2455\n",
      "Epoch 0 \t Iteration 8860 \t loss 0.1584\n",
      "Epoch 0 \t Iteration 8880 \t loss 0.2285\n",
      "Epoch 0 \t Iteration 8900 \t loss 0.2239\n",
      "Epoch 0 \t Iteration 8920 \t loss 0.2228\n",
      "Epoch 0 \t Iteration 8940 \t loss 0.1661\n",
      "Epoch 0 \t Iteration 8960 \t loss 0.1533\n",
      "Epoch 0 \t Iteration 8980 \t loss 0.2924\n",
      "Epoch 0 \t Iteration 9000 \t loss 0.2235\n",
      "Epoch 0 \t Iteration 9020 \t loss 0.2565\n",
      "Epoch 0 \t Iteration 9040 \t loss 0.1719\n",
      "Epoch 0 \t Iteration 9060 \t loss 0.2633\n",
      "Epoch 0 \t Iteration 9080 \t loss 0.2309\n",
      "Epoch 0 \t Iteration 9100 \t loss 0.1991\n",
      "Epoch 0 \t Iteration 9120 \t loss 0.1715\n",
      "Epoch 0 \t Iteration 9140 \t loss 0.2050\n",
      "Epoch 0 \t Iteration 9160 \t loss 0.1793\n",
      "Epoch 0 \t Iteration 9180 \t loss 0.2153\n",
      "Epoch 0 \t Iteration 9200 \t loss 0.1713\n",
      "Epoch 0 \t Iteration 9220 \t loss 0.2198\n",
      "Epoch 0 \t Iteration 9240 \t loss 0.2531\n",
      "Epoch 0 \t Iteration 9260 \t loss 0.2252\n",
      "Epoch 0 \t Iteration 9280 \t loss 0.1805\n",
      "Epoch 0 \t Iteration 9300 \t loss 0.2615\n",
      "Epoch 0 \t Iteration 9320 \t loss 0.2579\n",
      "Epoch 0 \t Iteration 9340 \t loss 0.2675\n",
      "Epoch 0 \t Iteration 9360 \t loss 0.2695\n",
      "Epoch 0 \t Iteration 9380 \t loss 0.2279\n",
      "Epoch 0 \t Iteration 9400 \t loss 0.1924\n",
      "Epoch 0 \t Iteration 9420 \t loss 0.2413\n",
      "Epoch 0 \t Iteration 9440 \t loss 0.2601\n",
      "Epoch 0 \t Iteration 9460 \t loss 0.2185\n",
      "Epoch 0 \t Iteration 9480 \t loss 0.1791\n",
      "Epoch 0 \t Iteration 9500 \t loss 0.2742\n",
      "Epoch 0 \t Iteration 9520 \t loss 0.2050\n",
      "Epoch 0 \t Iteration 9540 \t loss 0.1806\n",
      "Epoch 0 \t Iteration 9560 \t loss 0.2456\n",
      "Epoch 0 \t Iteration 9580 \t loss 0.2892\n",
      "Epoch 0 \t Iteration 9600 \t loss 0.2395\n",
      "Epoch 0 \t Iteration 9620 \t loss 0.2249\n",
      "Epoch 0 \t Iteration 9640 \t loss 0.2340\n",
      "Epoch 0 \t Iteration 9660 \t loss 0.2460\n",
      "Epoch 0 \t Iteration 9680 \t loss 0.1871\n",
      "Epoch 0 \t Iteration 9700 \t loss 0.2936\n",
      "Epoch 0 \t Iteration 9720 \t loss 0.2996\n",
      "Epoch 0 \t Iteration 9740 \t loss 0.2113\n",
      "Epoch 0 \t Iteration 9760 \t loss 0.1745\n",
      "Epoch 0 \t Iteration 9780 \t loss 0.2330\n",
      "Epoch 0 \t Iteration 9800 \t loss 0.1761\n",
      "Epoch 0 \t Iteration 9820 \t loss 0.2679\n",
      "Epoch 0 \t Iteration 9840 \t loss 0.2791\n",
      "Epoch 0 \t Iteration 9860 \t loss 0.2092\n",
      "Epoch 0 \t Iteration 9880 \t loss 0.2072\n",
      "Epoch 0 \t Iteration 9900 \t loss 0.1919\n",
      "Epoch 0 \t Iteration 9920 \t loss 0.3514\n",
      "Epoch 0 \t Iteration 9940 \t loss 0.2214\n",
      "Epoch 0 \t Iteration 9960 \t loss 0.2338\n",
      "Epoch 0 \t Iteration 9980 \t loss 0.1921\n",
      "Epoch 0 \t Iteration 10000 \t loss 0.2569\n",
      "Epoch 0 \t Iteration 10020 \t loss 0.2391\n",
      "Epoch 0 \t Iteration 10040 \t loss 0.2460\n",
      "Epoch 0 \t Iteration 10060 \t loss 0.1627\n",
      "Epoch 0 \t Iteration 10080 \t loss 0.2088\n",
      "Epoch 0 \t Iteration 10100 \t loss 0.1600\n",
      "Epoch 0 \t Iteration 10120 \t loss 0.2170\n",
      "Epoch 0 \t Iteration 10140 \t loss 0.2337\n",
      "Epoch 0 \t Iteration 10160 \t loss 0.1795\n",
      "Epoch 0 \t Iteration 10180 \t loss 0.2218\n",
      "Epoch 0 \t Iteration 10200 \t loss 0.2142\n",
      "Epoch 0 \t Iteration 10220 \t loss 0.1859\n",
      "Epoch 0 \t Iteration 10240 \t loss 0.2051\n",
      "Epoch 0 \t Iteration 10260 \t loss 0.2227\n",
      "Epoch 0 \t Iteration 10280 \t loss 0.2113\n",
      "Epoch 0 \t Iteration 10300 \t loss 0.1838\n",
      "Epoch 0 \t Iteration 10320 \t loss 0.2289\n",
      "Epoch 0 \t Iteration 10340 \t loss 0.3391\n",
      "Epoch 0 \t Iteration 10360 \t loss 0.1840\n",
      "Epoch 0 \t Iteration 10380 \t loss 0.2386\n",
      "Epoch 0 \t Iteration 10400 \t loss 0.1950\n",
      "Epoch 0 \t Iteration 10420 \t loss 0.1913\n",
      "Epoch 0 \t Iteration 10440 \t loss 0.1951\n",
      "Epoch 0 \t Iteration 10460 \t loss 0.2664\n",
      "Epoch 0 \t Iteration 10480 \t loss 0.1844\n",
      "Epoch 0 \t Iteration 10500 \t loss 0.2056\n",
      "Epoch 0 \t Iteration 10520 \t loss 0.1875\n",
      "Epoch 0 \t Iteration 10540 \t loss 0.1791\n",
      "Epoch 0 \t Iteration 10560 \t loss 0.2236\n",
      "Epoch 0 \t Iteration 10580 \t loss 0.2731\n",
      "Epoch 0 \t Iteration 10600 \t loss 0.2364\n",
      "Epoch 0 \t Iteration 10620 \t loss 0.2316\n",
      "Epoch 0 \t Iteration 10640 \t loss 0.2409\n",
      "Epoch 0 \t Iteration 10660 \t loss 0.2228\n",
      "Epoch 0 \t Iteration 10680 \t loss 0.2146\n",
      "Epoch 0 \t Iteration 10700 \t loss 0.1712\n",
      "Epoch 0 \t Iteration 10720 \t loss 0.1640\n",
      "Epoch 0 \t Iteration 10740 \t loss 0.1654\n",
      "Epoch 0 \t Iteration 10760 \t loss 0.2207\n",
      "Epoch 0 \t Iteration 10780 \t loss 0.1403\n",
      "Epoch 0 \t Iteration 10800 \t loss 0.2191\n",
      "Epoch 0 \t Iteration 10820 \t loss 0.2658\n",
      "Epoch 0 \t Iteration 10840 \t loss 0.2160\n",
      "Epoch 0 \t Iteration 10860 \t loss 0.1643\n",
      "Epoch 0 \t Iteration 10880 \t loss 0.2167\n",
      "Epoch 0 \t Iteration 10900 \t loss 0.1975\n",
      "Epoch 0 \t Iteration 10920 \t loss 0.1633\n",
      "Epoch 0 \t Iteration 10940 \t loss 0.2426\n",
      "Epoch 0 \t Iteration 10960 \t loss 0.1963\n",
      "Epoch 0 \t Iteration 10980 \t loss 0.2109\n",
      "Epoch 0 \t Iteration 11000 \t loss 0.2777\n",
      "Epoch 0 \t Iteration 11020 \t loss 0.2325\n",
      "Epoch 0 \t Iteration 11040 \t loss 0.2138\n",
      "Epoch 0 \t Iteration 11060 \t loss 0.1946\n",
      "Epoch 0 \t Iteration 11080 \t loss 0.2371\n",
      "Epoch 0 \t Iteration 11100 \t loss 0.2031\n",
      "Epoch 0 \t Iteration 11120 \t loss 0.2348\n",
      "Epoch 0 \t Iteration 11140 \t loss 0.1768\n",
      "Epoch 0 \t Iteration 11160 \t loss 0.2333\n",
      "Epoch 0 \t Iteration 11180 \t loss 0.2185\n",
      "Epoch 0 \t Iteration 11200 \t loss 0.2336\n",
      "Epoch 0 \t Iteration 11220 \t loss 0.2278\n",
      "Epoch 0 \t Iteration 11240 \t loss 0.3122\n",
      "Epoch 0 \t Iteration 11260 \t loss 0.2182\n",
      "Epoch 0 \t Iteration 11280 \t loss 0.2886\n",
      "Epoch 0 \t Iteration 11300 \t loss 0.1709\n",
      "Epoch 0 \t Iteration 11320 \t loss 0.2325\n",
      "Epoch 0 \t Iteration 11340 \t loss 0.3079\n",
      "Epoch 0 \t Iteration 11360 \t loss 0.3028\n",
      "Epoch 0 \t Iteration 11380 \t loss 0.3124\n",
      "Epoch 0 \t Iteration 11400 \t loss 0.2328\n",
      "Epoch 0 \t Iteration 11420 \t loss 0.2843\n",
      "Epoch 0 \t Iteration 11440 \t loss 0.2294\n",
      "Epoch 0 \t Iteration 11460 \t loss 0.2584\n",
      "Epoch 0 \t Iteration 11480 \t loss 0.2262\n",
      "Epoch 0 \t Iteration 11500 \t loss 0.2206\n",
      "Epoch 0 \t Iteration 11520 \t loss 0.2155\n",
      "Epoch 0 \t Iteration 11540 \t loss 0.1938\n",
      "Epoch 0 \t Iteration 11560 \t loss 0.1794\n",
      "Epoch 0 \t Iteration 11580 \t loss 0.2475\n",
      "Epoch 0 \t Iteration 11600 \t loss 0.2047\n",
      "Epoch 0 \t Iteration 11620 \t loss 0.2045\n",
      "Epoch 0 \t Iteration 11640 \t loss 0.1980\n",
      "Epoch 0 \t Iteration 11660 \t loss 0.2426\n",
      "Epoch 0 \t Iteration 11680 \t loss 0.2679\n",
      "Epoch 0 \t Iteration 11700 \t loss 0.2472\n",
      "Epoch 0 \t Iteration 11720 \t loss 0.2242\n",
      "Epoch 0 \t Iteration 11740 \t loss 0.2235\n",
      "Epoch 0 \t Iteration 11760 \t loss 0.2095\n",
      "Epoch 0 \t Iteration 11780 \t loss 0.2254\n",
      "Epoch 0 \t Iteration 11800 \t loss 0.1774\n",
      "Epoch 0 \t Iteration 11820 \t loss 0.2278\n",
      "Epoch 0 \t Iteration 11840 \t loss 0.1580\n",
      "Epoch 0 \t Iteration 11860 \t loss 0.1943\n",
      "Epoch 0 \t Iteration 11880 \t loss 0.1947\n",
      "Epoch 0 \t Iteration 11900 \t loss 0.1653\n",
      "Epoch 0 \t Iteration 11920 \t loss 0.2079\n",
      "Epoch 0 \t Iteration 11940 \t loss 0.2358\n",
      "Epoch 0 \t Iteration 11960 \t loss 0.2465\n",
      "Epoch 0 \t Iteration 11980 \t loss 0.2375\n",
      "Epoch 0 \t Iteration 12000 \t loss 0.1922\n",
      "Epoch 0 \t Iteration 12020 \t loss 0.1879\n",
      "Epoch 0 \t Iteration 12040 \t loss 0.1800\n",
      "Epoch 0 \t Iteration 12060 \t loss 0.1990\n",
      "Epoch 0 \t Iteration 12080 \t loss 0.2234\n",
      "Epoch 0 \t Iteration 12100 \t loss 0.1947\n",
      "Epoch 0 \t Iteration 12120 \t loss 0.2029\n",
      "Epoch 0 \t Iteration 12140 \t loss 0.2265\n",
      "Epoch 0 \t Iteration 12160 \t loss 0.2239\n",
      "Epoch 0 \t Iteration 12180 \t loss 0.1553\n",
      "Epoch 0 \t Iteration 12200 \t loss 0.2448\n",
      "Epoch 0 \t Iteration 12220 \t loss 0.2009\n",
      "Epoch 0 \t Iteration 12240 \t loss 0.2599\n",
      "Epoch 0 \t Iteration 12260 \t loss 0.2103\n",
      "Epoch 0 \t Iteration 12280 \t loss 0.2134\n",
      "Epoch 0 \t Iteration 12300 \t loss 0.2040\n",
      "Epoch 0 \t Iteration 12320 \t loss 0.1776\n",
      "Epoch 0 \t Iteration 12340 \t loss 0.1648\n",
      "Epoch 0 \t Iteration 12360 \t loss 0.1743\n",
      "Epoch 0 \t Iteration 12380 \t loss 0.2104\n",
      "Epoch 0 \t Iteration 12400 \t loss 0.2051\n",
      "Epoch 0 \t Iteration 12420 \t loss 0.2120\n",
      "Epoch 0 \t Iteration 12440 \t loss 0.2263\n",
      "Epoch 0 \t Iteration 12460 \t loss 0.3006\n",
      "Epoch 0 \t Iteration 12480 \t loss 0.2010\n",
      ">> valid \tEpoch 0 \t Iteration 0 \t loss 1.9411\n",
      ">> valid \tEpoch 0 \t Iteration 20 \t loss 1.8948\n",
      ">> valid \tEpoch 0 \t Iteration 40 \t loss 1.9861\n",
      ">> valid \tEpoch 0 \t Iteration 60 \t loss 1.5781\n",
      ">> valid \tEpoch 0 \t Iteration 80 \t loss 2.0080\n",
      ">> valid \tEpoch 0 \t Iteration 100 \t loss 1.8844\n",
      ">> valid \tEpoch 0 \t Iteration 120 \t loss 2.0110\n",
      ">> valid \tEpoch 0 \t Iteration 140 \t loss 2.5236\n",
      ">> valid \tEpoch 0 \t Iteration 160 \t loss 1.9035\n",
      ">> valid \tEpoch 0 \t Iteration 180 \t loss 1.7635\n",
      ">> valid \tEpoch 0 \t Iteration 200 \t loss 1.8426\n",
      ">> valid \tEpoch 0 \t Iteration 220 \t loss 2.0163\n",
      ">> valid \tEpoch 0 \t Iteration 240 \t loss 1.9674\n",
      ">> valid \tEpoch 0 \t Iteration 260 \t loss 1.8735\n",
      ">> valid \tEpoch 0 \t Iteration 280 \t loss 1.8972\n",
      ">> valid \tEpoch 0 \t Iteration 300 \t loss 1.9025\n",
      ">> valid \tEpoch 0 \t Iteration 320 \t loss 1.9360\n",
      ">> valid \tEpoch 0 \t Iteration 340 \t loss 2.0295\n",
      ">> valid \tEpoch 0 \t Iteration 360 \t loss 2.3592\n",
      ">> valid \tEpoch 0 \t Iteration 380 \t loss 1.7866\n",
      ">> valid \tEpoch 0 \t Iteration 400 \t loss 1.9174\n",
      ">> valid \tEpoch 0 \t Iteration 420 \t loss 2.0184\n",
      ">> valid \tEpoch 0 \t Iteration 440 \t loss 1.9166\n",
      ">> valid \tEpoch 0 \t Iteration 460 \t loss 1.9112\n",
      ">> valid \tEpoch 0 \t Iteration 480 \t loss 1.7101\n",
      ">> valid \tEpoch 0 \t Iteration 500 \t loss 1.9326\n",
      ">> valid \tEpoch 0 \t Iteration 520 \t loss 2.0962\n",
      ">> valid \tEpoch 0 \t Iteration 540 \t loss 1.8950\n",
      ">> valid \tEpoch 0 \t Iteration 560 \t loss 1.8948\n",
      ">> valid \tEpoch 0 \t Iteration 580 \t loss 2.0025\n",
      ">> valid \tEpoch 0 \t Iteration 600 \t loss 1.9350\n",
      ">> valid \tEpoch 0 \t Iteration 620 \t loss 1.9940\n",
      ">> valid \tEpoch 0 \t Iteration 640 \t loss 1.9808\n",
      ">> valid \tEpoch 0 \t Iteration 660 \t loss 2.0934\n",
      ">> valid \tEpoch 0 \t Iteration 680 \t loss 2.0766\n",
      ">> valid \tEpoch 0 \t Iteration 700 \t loss 1.8334\n",
      ">> valid \tEpoch 0 \t Iteration 720 \t loss 2.0792\n",
      ">> valid \tEpoch 0 \t Iteration 740 \t loss 2.0017\n",
      ">> valid \tEpoch 0 \t Iteration 760 \t loss 1.6630\n",
      ">> valid \tEpoch 0 \t Iteration 780 \t loss 2.1137\n",
      ">> valid \tEpoch 0 \t Iteration 800 \t loss 1.9202\n",
      ">> valid \tEpoch 0 \t Iteration 820 \t loss 2.1650\n",
      ">> valid \tEpoch 0 \t Iteration 840 \t loss 2.0735\n",
      ">> valid \tEpoch 0 \t Iteration 860 \t loss 1.6933\n",
      ">> valid \tEpoch 0 \t Iteration 880 \t loss 1.8370\n",
      ">> valid \tEpoch 0 \t Iteration 900 \t loss 2.3172\n",
      ">> valid \tEpoch 0 \t Iteration 920 \t loss 1.9660\n",
      ">> valid \tEpoch 0 \t Iteration 940 \t loss 1.8708\n",
      ">> valid \tEpoch 0 \t Iteration 960 \t loss 1.9476\n",
      ">> valid \tEpoch 0 \t Iteration 980 \t loss 2.0241\n",
      ">> valid \tEpoch 0 \t Iteration 1000 \t loss 2.1576\n",
      ">> valid \tEpoch 0 \t Iteration 1020 \t loss 1.8007\n",
      ">> valid \tEpoch 0 \t Iteration 1040 \t loss 1.9909\n",
      ">> valid \tEpoch 0 \t Iteration 1060 \t loss 1.9093\n",
      ">> valid \tEpoch 0 \t Iteration 1080 \t loss 1.9777\n",
      ">> valid \tEpoch 0 \t Iteration 1100 \t loss 1.5536\n",
      ">> valid \tEpoch 0 \t Iteration 1120 \t loss 2.0582\n",
      ">> valid \tEpoch 0 \t Iteration 1140 \t loss 2.0247\n",
      ">> valid \tEpoch 0 \t Iteration 1160 \t loss 1.7985\n",
      ">> valid \tEpoch 0 \t Iteration 1180 \t loss 1.7151\n",
      ">> valid \tEpoch 0 \t Iteration 1200 \t loss 2.1564\n",
      ">> valid \tEpoch 0 \t Iteration 1220 \t loss 2.1428\n",
      ">> valid \tEpoch 0 \t Iteration 1240 \t loss 1.8154\n",
      ">> valid \tEpoch 0 \t Iteration 1260 \t loss 1.9208\n",
      ">> valid \tEpoch 0 \t Iteration 1280 \t loss 1.8759\n",
      ">> valid \tEpoch 0 \t Iteration 1300 \t loss 1.8095\n",
      ">> valid \tEpoch 0 \t Iteration 1320 \t loss 1.5556\n",
      ">> valid \tEpoch 0 \t Iteration 1340 \t loss 1.8922\n",
      ">> valid \tEpoch 0 \t Iteration 1360 \t loss 1.6803\n",
      ">> valid \tEpoch 0 \t Iteration 1380 \t loss 1.5521\n",
      ">> valid \tEpoch 0 \t Iteration 1400 \t loss 2.0840\n",
      ">> valid \tEpoch 0 \t Iteration 1420 \t loss 1.7164\n",
      ">> valid \tEpoch 0 \t Iteration 1440 \t loss 2.0173\n",
      ">> valid \tEpoch 0 \t Iteration 1460 \t loss 1.8565\n",
      ">> valid \tEpoch 0 \t Iteration 1480 \t loss 1.8376\n",
      ">> valid \tEpoch 0 \t Iteration 1500 \t loss 2.0564\n",
      ">> valid \tEpoch 0 \t Iteration 1520 \t loss 2.2232\n",
      ">> valid \tEpoch 0 \t Iteration 1540 \t loss 1.6095\n",
      ">> valid \tEpoch 0 \t Iteration 1560 \t loss 1.7263\n",
      ">> valid \tEpoch 0 \t Iteration 1580 \t loss 1.9468\n",
      ">> valid \tEpoch 0 \t Iteration 1600 \t loss 2.1857\n",
      ">> valid \tEpoch 0 \t Iteration 1620 \t loss 2.0188\n",
      ">> valid \tEpoch 0 \t Iteration 1640 \t loss 1.8366\n",
      ">> valid \tEpoch 0 \t Iteration 1660 \t loss 1.7799\n",
      ">> valid \tEpoch 0 \t Iteration 1680 \t loss 2.0210\n",
      ">> valid \tEpoch 0 \t Iteration 1700 \t loss 1.7599\n",
      ">> valid \tEpoch 0 \t Iteration 1720 \t loss 2.0676\n",
      ">> valid \tEpoch 0 \t Iteration 1740 \t loss 1.8925\n",
      ">> valid \tEpoch 0 \t Iteration 1760 \t loss 2.1693\n",
      ">> valid \tEpoch 0 \t Iteration 1780 \t loss 2.1175\n",
      ">> valid \tEpoch 0 \t Iteration 1800 \t loss 2.1911\n",
      ">> valid \tEpoch 0 \t Iteration 1820 \t loss 1.9915\n",
      ">> valid \tEpoch 0 \t Iteration 1840 \t loss 1.7796\n",
      ">> valid \tEpoch 0 \t Iteration 1860 \t loss 1.8059\n",
      ">> valid \tEpoch 0 \t Iteration 1880 \t loss 2.1200\n",
      ">> valid \tEpoch 0 \t Iteration 1900 \t loss 1.8740\n",
      ">> valid \tEpoch 0 \t Iteration 1920 \t loss 1.7444\n",
      ">> valid \tEpoch 0 \t Iteration 1940 \t loss 2.0330\n",
      ">> valid \tEpoch 0 \t Iteration 1960 \t loss 2.0336\n",
      ">> valid \tEpoch 0 \t Iteration 1980 \t loss 1.8546\n",
      ">> valid \tEpoch 0 \t Iteration 2000 \t loss 1.8334\n",
      ">> valid \tEpoch 0 \t Iteration 2020 \t loss 1.8875\n",
      ">> valid \tEpoch 0 \t Iteration 2040 \t loss 2.1186\n",
      ">> valid \tEpoch 0 \t Iteration 2060 \t loss 1.8171\n",
      ">> valid \tEpoch 0 \t Iteration 2080 \t loss 2.2723\n",
      ">> valid \tEpoch 0 \t Iteration 2100 \t loss 1.6368\n",
      ">> valid \tEpoch 0 \t Iteration 2120 \t loss 2.0084\n",
      ">> valid \tEpoch 0 \t Iteration 2140 \t loss 1.9224\n",
      ">> valid \tEpoch 0 \t Iteration 2160 \t loss 1.9721\n",
      ">> valid \tEpoch 0 \t Iteration 2180 \t loss 2.0611\n",
      ">> valid \tEpoch 0 \t Iteration 2200 \t loss 1.8221\n",
      ">> test \tEpoch 0 \t Iteration 0 \t loss 1.2336\n",
      ">> test \tEpoch 0 \t Iteration 20 \t loss 2.0628\n",
      ">> test \tEpoch 0 \t Iteration 40 \t loss 1.8277\n",
      ">> test \tEpoch 0 \t Iteration 60 \t loss 1.9127\n",
      ">> test \tEpoch 0 \t Iteration 80 \t loss 1.8547\n",
      ">> test \tEpoch 0 \t Iteration 100 \t loss 1.9085\n",
      ">> test \tEpoch 0 \t Iteration 120 \t loss 1.9991\n",
      ">> test \tEpoch 0 \t Iteration 140 \t loss 1.8475\n",
      ">> test \tEpoch 0 \t Iteration 160 \t loss 1.9011\n",
      ">> test \tEpoch 0 \t Iteration 180 \t loss 1.8874\n",
      ">> test \tEpoch 0 \t Iteration 200 \t loss 1.9368\n",
      ">> test \tEpoch 0 \t Iteration 220 \t loss 1.9002\n",
      ">> test \tEpoch 0 \t Iteration 240 \t loss 2.1450\n",
      ">> test \tEpoch 0 \t Iteration 260 \t loss 2.0483\n",
      ">> test \tEpoch 0 \t Iteration 280 \t loss 1.9937\n",
      ">> test \tEpoch 0 \t Iteration 300 \t loss 2.3337\n",
      ">> test \tEpoch 0 \t Iteration 320 \t loss 1.8765\n",
      ">> test \tEpoch 0 \t Iteration 340 \t loss 2.0935\n",
      ">> test \tEpoch 0 \t Iteration 360 \t loss 1.8499\n",
      ">> test \tEpoch 0 \t Iteration 380 \t loss 2.2772\n",
      ">> test \tEpoch 0 \t Iteration 400 \t loss 2.2297\n",
      ">> test \tEpoch 0 \t Iteration 420 \t loss 1.9183\n",
      ">> test \tEpoch 0 \t Iteration 440 \t loss 1.8785\n",
      ">> test \tEpoch 0 \t Iteration 460 \t loss 1.8671\n",
      ">> test \tEpoch 0 \t Iteration 480 \t loss 2.1657\n",
      ">> test \tEpoch 0 \t Iteration 500 \t loss 1.9689\n",
      ">> test \tEpoch 0 \t Iteration 520 \t loss 1.6606\n",
      ">> test \tEpoch 0 \t Iteration 540 \t loss 1.8400\n",
      ">> test \tEpoch 0 \t Iteration 560 \t loss 2.0756\n",
      ">> test \tEpoch 0 \t Iteration 580 \t loss 1.7098\n",
      ">> test \tEpoch 0 \t Iteration 600 \t loss 2.2834\n",
      ">> test \tEpoch 0 \t Iteration 620 \t loss 1.5820\n",
      ">> test \tEpoch 0 \t Iteration 640 \t loss 1.8084\n",
      ">> test \tEpoch 0 \t Iteration 660 \t loss 1.9713\n",
      ">> test \tEpoch 0 \t Iteration 680 \t loss 1.7600\n",
      ">> test \tEpoch 0 \t Iteration 700 \t loss 2.0473\n",
      ">> test \tEpoch 0 \t Iteration 720 \t loss 1.8885\n",
      ">> test \tEpoch 0 \t Iteration 740 \t loss 1.7975\n",
      ">> test \tEpoch 0 \t Iteration 760 \t loss 1.7651\n",
      ">> test \tEpoch 0 \t Iteration 780 \t loss 1.8804\n",
      ">> test \tEpoch 0 \t Iteration 800 \t loss 1.6578\n",
      ">> test \tEpoch 0 \t Iteration 820 \t loss 1.8673\n",
      ">> test \tEpoch 0 \t Iteration 840 \t loss 1.9300\n",
      ">> test \tEpoch 0 \t Iteration 860 \t loss 1.7873\n",
      ">> test \tEpoch 0 \t Iteration 880 \t loss 1.7187\n",
      ">> test \tEpoch 0 \t Iteration 900 \t loss 1.9525\n",
      ">> test \tEpoch 0 \t Iteration 920 \t loss 1.9067\n",
      ">> test \tEpoch 0 \t Iteration 940 \t loss 1.7371\n",
      ">> test \tEpoch 0 \t Iteration 960 \t loss 1.7459\n",
      ">> test \tEpoch 0 \t Iteration 980 \t loss 1.8767\n",
      ">> test \tEpoch 0 \t Iteration 1000 \t loss 1.9258\n",
      ">> test \tEpoch 0 \t Iteration 1020 \t loss 1.9205\n",
      ">> test \tEpoch 0 \t Iteration 1040 \t loss 1.5593\n",
      ">> test \tEpoch 0 \t Iteration 1060 \t loss 2.0005\n",
      ">> test \tEpoch 0 \t Iteration 1080 \t loss 2.3118\n",
      ">> test \tEpoch 0 \t Iteration 1100 \t loss 1.8335\n",
      ">> test \tEpoch 0 \t Iteration 1120 \t loss 1.6408\n",
      ">> test \tEpoch 0 \t Iteration 1140 \t loss 2.1386\n",
      ">> test \tEpoch 0 \t Iteration 1160 \t loss 1.6913\n",
      ">> test \tEpoch 0 \t Iteration 1180 \t loss 2.0548\n",
      ">> test \tEpoch 0 \t Iteration 1200 \t loss 2.1117\n",
      ">> test \tEpoch 0 \t Iteration 1220 \t loss 2.1881\n",
      ">> test \tEpoch 0 \t Iteration 1240 \t loss 1.7732\n",
      ">> test \tEpoch 0 \t Iteration 1260 \t loss 2.0844\n",
      ">> test \tEpoch 0 \t Iteration 1280 \t loss 2.0208\n",
      ">> test \tEpoch 0 \t Iteration 1300 \t loss 1.8048\n",
      ">> test \tEpoch 0 \t Iteration 1320 \t loss 1.8685\n",
      ">> test \tEpoch 0 \t Iteration 1340 \t loss 1.6768\n",
      ">> test \tEpoch 0 \t Iteration 1360 \t loss 2.3914\n",
      ">> test \tEpoch 0 \t Iteration 1380 \t loss 1.6430\n",
      ">> test \tEpoch 0 \t Iteration 1400 \t loss 3.4144\n",
      ">> test \tEpoch 0 \t Iteration 1420 \t loss 2.0929\n",
      ">> test \tEpoch 0 \t Iteration 1440 \t loss 2.0072\n",
      ">> test \tEpoch 0 \t Iteration 1460 \t loss 1.7083\n",
      ">> test \tEpoch 0 \t Iteration 1480 \t loss 1.7371\n",
      ">> test \tEpoch 0 \t Iteration 1500 \t loss 1.9400\n",
      ">> test \tEpoch 0 \t Iteration 1520 \t loss 1.8791\n",
      ">> test \tEpoch 0 \t Iteration 1540 \t loss 1.6465\n",
      ">> test \tEpoch 0 \t Iteration 1560 \t loss 2.3357\n",
      ">> test \tEpoch 0 \t Iteration 1580 \t loss 2.2832\n",
      ">> test \tEpoch 0 \t Iteration 1600 \t loss 1.6860\n",
      ">> test \tEpoch 0 \t Iteration 1620 \t loss 1.9960\n",
      "Val loss: 1.9320 \t test loss: 1.9239 \t epoch 0\n",
      "Best: val loss: 1.9320 \t test loss: 1.9239 \t epoch 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kieran/forward-pred/WIP_6_13_22.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kieran/forward-pred/WIP_6_13_22.ipynb#ch0000007?line=14'>15</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mVal loss: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m test loss: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m epoch \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (val_loss, test_loss, epoch))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kieran/forward-pred/WIP_6_13_22.ipynb#ch0000007?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: val loss: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m test loss: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m epoch \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (res[\u001b[39m'\u001b[39m\u001b[39mbest_val\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mbest_test\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mbest_epoch\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kieran/forward-pred/WIP_6_13_22.ipynb#ch0000007?line=18'>19</a>\u001b[0m json_object \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(res, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kieran/forward-pred/WIP_6_13_22.ipynb#ch0000007?line=19'>20</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(args\u001b[39m.\u001b[39moutf \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m args\u001b[39m.\u001b[39mexp_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/losess.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m outfile:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kieran/forward-pred/WIP_6_13_22.ipynb#ch0000007?line=20'>21</a>\u001b[0m     outfile\u001b[39m.\u001b[39mwrite(json_object)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "res = {'epochs': [], 'losess': [], 'best_val': 1e10, 'best_test': 1e10, 'best_epoch': 0}\n",
    "\n",
    "for epoch in range(0, args.epochs):\n",
    "    train(epoch, dataloaders['train'], partition='train')\n",
    "    if epoch % args.test_interval == 0:\n",
    "        val_loss = train(epoch, dataloaders['valid'], partition='valid')\n",
    "        test_loss = train(epoch, dataloaders['test'], partition='test')\n",
    "        res['epochs'].append(epoch)\n",
    "        res['losess'].append(test_loss)\n",
    "\n",
    "        if val_loss < res['best_val']:\n",
    "            res['best_val'] = val_loss\n",
    "            res['best_test'] = test_loss\n",
    "            res['best_epoch'] = epoch\n",
    "        print(\"Val loss: %.4f \\t test loss: %.4f \\t epoch %d\" % (val_loss, test_loss, epoch))\n",
    "        print(\"Best: val loss: %.4f \\t test loss: %.4f \\t epoch %d\" % (res['best_val'], res['best_test'], res['best_epoch']))\n",
    "\n",
    "\n",
    "    json_object = json.dumps(res, indent=4)\n",
    "    with open(args.outf + \"/\" + args.exp_name + \"/losess.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import egnn_clean as eg\n",
    "import torch\n",
    "\n",
    "# Dummy parameters\n",
    "batch_size = 8\n",
    "n_nodes = 4\n",
    "n_feat = 1\n",
    "x_dim = 3\n",
    "\n",
    "# Dummy variables h, x and fully connected edges\n",
    "h = torch.ones(batch_size * n_nodes, n_feat)\n",
    "x = torch.ones(batch_size * n_nodes, x_dim)\n",
    "edges, edge_attr = eg.get_edges_batch(n_nodes, batch_size)\n",
    "\n",
    "# Initialize EGNN\n",
    "egnn = eg.EGNN(in_node_nf=n_feat, hidden_nf=32, out_node_nf=1, in_edge_nf=1)\n",
    "\n",
    "# Run EGNN\n",
    "h, x = egnn(h, x, edges, edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -u main_qm9.py --num_workers 2 --lr 5e-4 --property alpha --exp_name exp_1_alpha"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75045139ea58b4fb571e03dddc527b13688015b7207563deeac5a7900d487c59"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('forward')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
